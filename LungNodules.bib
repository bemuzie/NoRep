
@article{obuchowski_quantitative_2015,
  title = {Quantitative Imaging Biomarkers: A Review of Statistical Methods for Computer Algorithm Comparisons},
  volume = {24},
  issn = {1477-0334},
  doi = {10.1177/0962280214537390},
  shorttitle = {Quantitative Imaging Biomarkers},
  abstract = {Quantitative biomarkers from medical images are becoming important tools for clinical diagnosis, staging, monitoring, treatment planning, and development of new therapies. While there is a rich history of the development of quantitative imaging biomarker (QIB) techniques, little attention has been paid to the validation and comparison of the computer algorithms that implement the QIB measurements. In this paper we provide a framework for QIB algorithm comparisons. We first review and compare various study designs, including designs with the true value (e.g. phantoms, digital reference images, and zero-change studies), designs with a reference standard (e.g. studies testing equivalence with a reference standard), and designs without a reference standard (e.g. agreement studies and studies of algorithm precision). The statistical methods for comparing QIB algorithms are then presented for various study types using both aggregate and disaggregate approaches. We propose a series of steps for establishing the performance of a QIB algorithm, identify limitations in the current statistical literature, and suggest future directions for research.},
  timestamp = {2017-05-15T15:37:54Z},
  langid = {english},
  number = {1},
  journaltitle = {Statistical Methods in Medical Research},
  shortjournal = {Stat Methods Med Res},
  author = {Obuchowski, Nancy A. and Reeves, Anthony P. and Huang, Erich P. and Wang, Xiao-Feng and Buckler, Andrew J. and Kim, Hyun J. Grace and Barnhart, Huiman X. and Jackson, Edward F. and Giger, Maryellen L. and Pennello, Gene and Toledano, Alicia Y. and Kalpathy-Cramer, Jayashree and Apanasovich, Tatiyana V. and Kinahan, Paul E. and Myers, Kyle J. and Goldgof, Dmitry B. and Barboriak, Daniel P. and Gillies, Robert J. and Schwartz, Lawrence H. and Sullivan, Daniel C. and {Algorithm Comparison Working Group}},
  date = {2015-02},
  pages = {68--106},
  keywords = {agreement,Algorithms,bias,Bias (Epidemiology),BIOMARKERS,Computer Simulation,Diagnostic Imaging,Humans,image metrics,imaging biomarkers,Phantoms; Imaging,precision,quantitative imaging,Reference Standards,repeatability,reproducibility,Reproducibility of Results,Research Design,Statistics as Topic},
  eprinttype = {pmid},
  eprint = {24919829},
  pmcid = {PMC4263694}
}

@article{therasse_new_2000,
  title = {New Guidelines to Evaluate the Response to Treatment in Solid Tumors. {{European Organization}} for {{Research}} and {{Treatment}} of {{Cancer}}, {{National Cancer Institute}} of the {{United States}}, {{National Cancer Institute}} of {{Canada}}},
  volume = {92},
  issn = {0027-8874},
  abstract = {Anticancer cytotoxic agents go through a process by which their antitumor activity-on the basis of the amount of tumor shrinkage they could generate-has been investigated. In the late 1970s, the International Union Against Cancer and the World Health Organization introduced specific criteria for the codification of tumor response evaluation. In 1994, several organizations involved in clinical research combined forces to tackle the review of these criteria on the basis of the experience and knowledge acquired since then. After several years of intensive discussions, a new set of guidelines is ready that will supersede the former criteria. In parallel to this initiative, one of the participating groups developed a model by which response rates could be derived from unidimensional measurement of tumor lesions instead of the usual bidimensional approach. This new concept has been largely validated by the Response Evaluation Criteria in Solid Tumors Group and integrated into the present guidelines. This special article also provides some philosophic background to clarify the various purposes of response evaluation. It proposes a model by which a combined assessment of all existing lesions, characterized by target lesions (to be measured) and nontarget lesions, is used to extrapolate an overall response to treatment. Methods of assessing tumor lesions are better codified, briefly within the guidelines and in more detail in Appendix I. All other aspects of response evaluation have been discussed, reviewed, and amended whenever appropriate.},
  timestamp = {2017-05-15T12:57:36Z},
  langid = {english},
  number = {3},
  journaltitle = {Journal of the National Cancer Institute},
  shortjournal = {J. Natl. Cancer Inst.},
  author = {Therasse, P. and Arbuck, S. G. and Eisenhauer, E. A. and Wanders, J. and Kaplan, R. S. and Rubinstein, L. and Verweij, J. and Van Glabbeke, M. and van Oosterom, A. T. and Christian, M. C. and Gwyther, S. G.},
  date = {2000-02-02},
  pages = {205--216},
  keywords = {Antineoplastic Agents,Biomarkers; Tumor,Clinical Trials as Topic,Disease-Free Survival,Endoscopy,Humans,Neoplasms,Outcome Assessment (Health Care),Radiography,Retrospective Studies,Treatment Outcome,Ultrasonography},
  options = {useprefix=true},
  eprinttype = {pmid},
  eprint = {10655437}
}

@article{eisenhauer_new_2009,
  title = {New Response Evaluation Criteria in Solid Tumours: Revised {{RECIST}} Guideline (Version 1.1)},
  volume = {45},
  issn = {1879-0852},
  doi = {10.1016/j.ejca.2008.10.026},
  shorttitle = {New Response Evaluation Criteria in Solid Tumours},
  abstract = {BACKGROUND: Assessment of the change in tumour burden is an important feature of the clinical evaluation of cancer therapeutics: both tumour shrinkage (objective response) and disease progression are useful endpoints in clinical trials. Since RECIST was published in 2000, many investigators, cooperative groups, industry and government authorities have adopted these criteria in the assessment of treatment outcomes. However, a number of questions and issues have arisen which have led to the development of a revised RECIST guideline (version 1.1). Evidence for changes, summarised in separate papers in this special issue, has come from assessment of a large data warehouse ($>$6500 patients), simulation studies and literature reviews. HIGHLIGHTS OF REVISED RECIST 1.1: Major changes include: Number of lesions to be assessed: based on evidence from numerous trial databases merged into a data warehouse for analysis purposes, the number of lesions required to assess tumour burden for response determination has been reduced from a maximum of 10 to a maximum of five total (and from five to two per organ, maximum). Assessment of pathological lymph nodes is now incorporated: nodes with a short axis of 15 mm are considered measurable and assessable as target lesions. The short axis measurement should be included in the sum of lesions in calculation of tumour response. Nodes that shrink to $<$10mm short axis are considered normal. Confirmation of response is required for trials with response primary endpoint but is no longer required in randomised studies since the control arm serves as appropriate means of interpretation of data. Disease progression is clarified in several aspects: in addition to the previous definition of progression in target disease of 20\% increase in sum, a 5mm absolute increase is now required as well to guard against over calling PD when the total sum is very small. Furthermore, there is guidance offered on what constitutes 'unequivocal progression' of non-measurable/non-target disease, a source of confusion in the original RECIST guideline. Finally, a section on detection of new lesions, including the interpretation of FDG-PET scan assessment is included. Imaging guidance: the revised RECIST includes a new imaging appendix with updated recommendations on the optimal anatomical assessment of lesions.
FUTURE WORK: A key question considered by the RECIST Working Group in developing RECIST 1.1 was whether it was appropriate to move from anatomic unidimensional assessment of tumour burden to either volumetric anatomical assessment or to functional assessment with PET or MRI. It was concluded that, at present, there is not sufficient standardisation or evidence to abandon anatomical assessment of tumour burden. The only exception to this is in the use of FDG-PET imaging as an adjunct to determination of progression. As is detailed in the final paper in this special issue, the use of these promising newer approaches requires appropriate clinical validation studies.},
  timestamp = {2017-05-17T10:01:32Z},
  langid = {english},
  number = {2},
  journaltitle = {European Journal of Cancer (Oxford, England: 1990)},
  shortjournal = {Eur. J. Cancer},
  author = {Eisenhauer, E. A. and Therasse, P. and Bogaerts, J. and Schwartz, L. H. and Sargent, D. and Ford, R. and Dancey, J. and Arbuck, S. and Gwyther, S. and Mooney, M. and Rubinstein, L. and Shankar, L. and Dodd, L. and Kaplan, R. and Lacombe, D. and Verweij, J.},
  date = {2009-01},
  pages = {228--247},
  keywords = {Clinical Trials as Topic,Disease Progression,Europe,Humans,Lymph Nodes,Magnetic Resonance Imaging,Neoplasms,Tomography; X-Ray Computed,Treatment Outcome},
  eprinttype = {pmid},
  eprint = {19097774}
}

@article{_quantitative_2015,
  title = {Quantitative {{Imaging Biomarkers}}: {{A Review}} of {{Statistical Methods}} for {{Computer Algorithm Comparisons}}},
  volume = {24},
  issn = {0962-2802},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4263694/},
  doi = {10.1177/0962280214537390},
  shorttitle = {Quantitative {{Imaging Biomarkers}}},
  abstract = {Quantitative biomarkers from medical images are becoming important tools for clinical diagnosis, staging, monitoring, treatment planning, and development of new therapies. While there is a rich history of the development of quantitative imaging biomarker (QIB) techniques, little attention has been paid to the validation and comparison of the computer algorithms that implement the QIB measurements. In this paper we provide a framework for QIB algorithm comparisons. We first review and compare various study designs, including designs with the true value (e.g. phantoms, digital reference images, and zero-change studies), designs with a reference standard (e.g. studies testing equivalence with a reference standard), and designs without a reference standard (e.g. agreement studies and studies of algorithm precision). The statistical methods for comparing QIB algorithms are then presented for various study types using both aggregate and disaggregate approaches. We propose a series of steps for establishing the performance of a QIB algorithm, identify limitations in the current statistical literature, and suggest future directions for research.},
  timestamp = {2017-05-18T09:04:12Z},
  number = {1},
  journaltitle = {Statistical methods in medical research},
  shortjournal = {Stat Methods Med Res},
  date = {2015-02},
  pages = {68--106},
  file = {PubMed Central Full Text PDF:/home/denest/.zotero/zotero/2qy5h4qb.default/zotero/storage/T98PEBDU/2015 - Quantitative Imaging Biomarkers A Review of Stati.pdf:application/pdf},
  eprinttype = {pmid},
  eprint = {24919829},
  pmcid = {PMC4263694}
}


